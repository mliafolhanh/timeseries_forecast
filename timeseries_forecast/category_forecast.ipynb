{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_process import *\n",
    "import datalabframework\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "from elastictools.doctools import DocTools\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = '/opt/conda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_elastic(flat_result_all_cat, index_name, doctype):\n",
    "    settings = {\n",
    "        \"index\":{\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1,\n",
    "            \"mapping\": {\n",
    "                \"total_fields\":{\n",
    "                    \"limit\": \"1000\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    mapping = {\n",
    "            doctype: { \n",
    "               \"dynamic_templates\": [\n",
    "                   {\"strings\": {\n",
    "                        \"match_mapping_type\": \"string\",\n",
    "                        \"mapping\": {\n",
    "                          \"type\": \"keyword\"\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    uri = ['http://{}:{}'.format(ip, '9200') for ip in ['192.168.0.179', '192.168.0.178']]\n",
    "    es = DocTools(uri)\n",
    "    esi = es.indextool()\n",
    "    esi.create(index_name, overwrite=True, settings=settings, mapping=mapping)\n",
    "    res = es.bulk(index_name, flat_result_all_cat, doctype=doctype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_category(product_quantity_date, cat_name = None, cat_root_name = None):\n",
    "    \"\"\"\n",
    "    Select all transactions of a category (or all products) and caculate total sale of this category by date.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    product_quantity_date: Spark.DataFrame\n",
    "        Arregation quantity dataframe of all sku and transaction date\n",
    "    cat_name: string\n",
    "        Name of selected category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Spark.DataFrame\n",
    "        Total sales of a category by date\n",
    "    \"\"\"\n",
    "    if cat_name:\n",
    "        cat_trans = product_quantity_date[product_quantity_date['cat_name'] == cat_name]\n",
    "    elif cat_root_name:\n",
    "        cat_trans = product_quantity_date[product_quantity_date['cat_root_name'] == cat_root_name]\n",
    "    else:\n",
    "        cat_trans = product_quantity_date[product_quantity_date['sku_id']!= \"1206838\"]\\\n",
    "                                         [product_quantity_date['sku_id']!= \"1207652\"]\n",
    "    total_by_date = cat_trans.groupby('transaction_date').agg({'daily_quantity':'sum'}).reset_index()\n",
    "    return total_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_func():\n",
    "    dlf = datalabframework.project.load()\n",
    "    engine = datalabframework.project.engine()\n",
    "    spark = engine.context()\n",
    "    fact_transaction = engine.load('fact_table').select('sku_id', 'sku_name', 'transaction_date', 'quantity', \\\n",
    "                                                        'doc_type', 'unit_price', 'cat_id', 'cat_group_id', \\\n",
    "                                                        'cat_root_id', 'cat_name', 'cat_group_name', 'cat_root_name')\n",
    "    product_quantity_date = fact_transaction.where(F.expr('doc_type == \"PTX\"') | F.expr('doc_type == \"HDF\"'))\\\n",
    "                .where(F.expr('unit_price != 0'))\\\n",
    "                .groupby('sku_id', 'sku_name', 'transaction_date', 'cat_id', 'cat_group_id', 'cat_root_id', 'cat_name', 'cat_group_name', 'cat_root_name')\\\n",
    "                .agg(F.sum('quantity').alias('daily_quantity'), F.avg('unit_price').alias('daily_price'))\\\n",
    "                .orderBy('transaction_date')\n",
    "    # .values return a numpy array, each row of which is array of values in a row in pandas df\n",
    "    all_cat_name = product_quantity_date.select('cat_name', 'cat_id').distinct().toPandas()[['cat_name', 'cat_id']].values\n",
    "    all_cat_root_name = product_quantity_date.select('cat_root_name', 'cat_root_id').distinct().toPandas()[['cat_root_name', 'cat_root_id']].values\n",
    "    all_cat = []\n",
    "    for cat_name in all_cat_name:\n",
    "        all_cat.append((tuple(cat_name), (cat_name[0], None)))\n",
    "    for cat_root_name in all_cat_root_name:\n",
    "        if cat_root_name not in all_cat_name:\n",
    "            all_cat.append((tuple(cat_root_name), (None, cat_root_name[0])))\n",
    "    all_cat.append((tuple(['total', '000000']), (None, None)))\n",
    "    product_quantity_date = product_quantity_date.toPandas()\n",
    "    product_quantity_date['daily_quantity'] = product_quantity_date['daily_quantity'].astype(np.int64)\n",
    "    product_quantity_date['transaction_date'] = pd.to_datetime(product_quantity_date['transaction_date'])\n",
    "    return product_quantity_date, all_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    product_quantity_date, all_cat = init_func()\n",
    "    for cat in all_cat:\n",
    "        if (cat[1][0] == None) & (cat[1][1] == None) & (cat[0][1] == None):\n",
    "            all_cat.remove(cat)\n",
    "    return product_quantity_date, all_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_history_and_forecast(product_quantity_date, cat, freq_ = 'D'):\n",
    "    total_by_date = select_category(product_quantity_date, *cat[1])\n",
    "    flat_result_cv, flat_result_test, hist_data, preds = adaptive_forecast_process(total_by_date, freq_)\n",
    "    if not flat_result_test:\n",
    "        return None, None, None, None\n",
    "    flat_result_test.update({'cat_name': cat[0][0], 'cat_id': cat[0][1]})\n",
    "    for result in flat_result_cv:\n",
    "        result.update({'cat_name': cat[0][0], 'cat_id': cat[0][1]})\n",
    "    for pred in preds:\n",
    "        pred.update({'cat_name': cat[0][0], 'cat_id': cat[0][1]})\n",
    "    for hist in hist_data:\n",
    "        hist.update({'cat_name': cat[0][0], 'cat_id': cat[0][1]})\n",
    "    return flat_result_cv, flat_result_test, hist_data, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(freq_str, product_quantity_date, all_cat):\n",
    "    freq_ = 'D'\n",
    "    if freq_str == 'month':\n",
    "        freq_ = 'M'\n",
    "    elif freq_str == 'week':\n",
    "        freq_ = 'W-SUN'\n",
    "    flat_test_result_all_cat = []\n",
    "    flat_cv_result_all_cat = []\n",
    "    history_data = []\n",
    "    preds_future = []\n",
    "    n = 0\n",
    "    for cat in all_cat:\n",
    "        print(n, ' ', cat)\n",
    "        n += 1\n",
    "        flat_result_cv, flat_result_test, hist_data, preds = caculate_history_and_forecast(product_quantity_date, cat, freq_)\n",
    "        if flat_result_test:\n",
    "            flat_test_result_all_cat.append(flat_result_test)\n",
    "        if flat_result_cv:\n",
    "            flat_cv_result_all_cat.extend(flat_result_cv)\n",
    "        if hist_data:\n",
    "            history_data.extend(hist_data)\n",
    "        if preds:\n",
    "            preds_future.extend(preds)\n",
    "    json.dump(flat_test_result_all_cat, open('json_output/category/' + freq_str + '/info_on_test.json', 'w', encoding = 'utf8'))\n",
    "    json.dump(flat_cv_result_all_cat, open('json_output/category/' + freq_str + '/info_on_cv.json','w', encoding = 'utf8'))\n",
    "    json.dump(history_data, open('json_output/category/' + freq_str + '/history_data.json','w', encoding = 'utf8'))\n",
    "    json.dump(preds_future, open('json_output/category/' + freq_str + '/future_prediction.json', 'w', encoding = 'utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_quantity_date, all_cat = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cat = [cat for cat in all_cat if cat[1][1]=='laptop']\n",
    "tmp_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('month', product_quantity_date, tmp_cat)\n",
    "# run('month', product_quantity_date, all_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('week', product_quantity_date, tmp_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('day', product_quantity_date, tmp_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_future = json.load(open('json_output/category/' + 'day'+ '/future_prediction.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = json.load(open('json_output/category/' + 'day'+ '/history_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(preds_future, 'hanh_forecast_category_day_prediction', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(history, 'hanh_forecast_category_day_history', 'history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_quantity_date, all_cat = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(product_quantity_date['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_by_date = select_category(product_quantity_date, None, 'laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_result_cv, flat_result_test, history_data, future_preds = adaptive_forecast_process(total_by_date, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(flat_result_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = (('loa bluetooth jbl', '06-N001-02-12'), ('loa bluetooth jbl', None))\n",
    "flat_result_cv, flat_result_test, hist_data, preds = caculate_history_and_forecast(product_quantity_date, cat, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(flat_result_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
