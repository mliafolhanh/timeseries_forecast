{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_elastic(flat_result_all_cat, index_name, doctype):\n",
    "    settings = {\n",
    "        \"index\":{\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1,\n",
    "            \"mapping\": {\n",
    "                \"total_fields\":{\n",
    "                    \"limit\": \"1000\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    mapping = {\n",
    "            doctype: { \n",
    "               \"dynamic_templates\": [\n",
    "                   {\"strings\": {\n",
    "                        \"match_mapping_type\": \"string\",\n",
    "                        \"mapping\": {\n",
    "                          \"type\": \"keyword\"\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    uri = ['http://{}:{}'.format(ip, '9200') for ip in ['192.168.0.179', '192.168.0.178']]\n",
    "    es = DocTools(uri)\n",
    "    esi = es.indextool()\n",
    "    esi.create(index_name, overwrite = True, settings = settings, mapping = mapping)\n",
    "    res = es.bulk(index_name, flat_result_all_cat, doctype = doctype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    #load fact\n",
    "    dlf = datalabframework.project.load()\n",
    "    engine = dlf.engine()\n",
    "    spark = engine.context()\n",
    "    fact_transaction = engine.load('fact_table').select('sku_id', 'sku_name', 'transaction_date', 'quantity', \\\n",
    "                                                        'doc_type', 'unit_price', 'cat_id', 'cat_group_id', \\\n",
    "                                                        'cat_root_id', 'cat_name', 'cat_group_name', 'cat_root_name',\\\n",
    "                                                        'brand_id', 'brand_name')\n",
    "    product_quantity_date = fact_transaction.where(F.expr('doc_type == \"PTX\"') | F.expr('doc_type == \"HDF\"'))\\\n",
    "                .where(F.expr('unit_price != 0'))\\\n",
    "                .groupby('sku_id', 'sku_name', 'transaction_date', 'cat_id', 'cat_group_id', 'cat_root_id', 'cat_name', \\\n",
    "                         'cat_group_name', 'cat_root_name', 'brand_id', 'brand_name')\\\n",
    "                .agg(F.sum('quantity').alias('daily_quantity'), F.avg('unit_price').alias('daily_price'))\\\n",
    "                .orderBy('transaction_date')\n",
    "    product_list = fact_transaction.where(F.col('product_state_id') == 1).select('sku_id', 'sku_name', 'quantity', 'unit_price')\\\n",
    "                .withColumn('revenue', F.col('quantity') * F.col('unit_price'))\\\n",
    "                .groupby('sku_id', 'sku_name').agg(F.sum('revenue').alias('total_revenue'))\\\n",
    "                .sort(F.desc('total_revenue')).toPandas()[['sku_id', 'sku_name']].values\n",
    "    product_quantity_date = product_quantity_date.toPandas()\n",
    "    product_quantity_date['daily_quantity'] = product_quantity_date['daily_quantity'].astype(np.int64)\n",
    "    product_quantity_date['transaction_date'] = pd.to_datetime(product_quantity_date['transaction_date'])\n",
    "    return product_quantity_date, product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trans(product_quantity_date, sku_id):\n",
    "    total_by_date = product_quantity_date[product_quantity_date['sku_id'] == sku_id]\n",
    "    total_by_date = total_by_date.groupby('transaction_date').agg({'daily_quantity':'sum'}).reset_index()\n",
    "    return total_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_quantity_date, product_list = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test_result_all_product = json.load(open('json_output/month_flat_test_result_all_product.json', 'r'))\n",
    "flat_cv_result_all_product = json.load(open('json_output/month_flat_cv_result_all_product.json', 'r'))\n",
    "preds_future = json.load(open('json_output/month_future_predict_all_product.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(flat_test_result_all_product, 'month_flat_test_result_all_product', 'month_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(preds_future, 'month_future_predict_all_product', 'month_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3000\n",
    "# flat_test_result_all_product = []\n",
    "# flat_cv_result_all_product = []\n",
    "# preds_future = []\n",
    "for product in product_list[3000:5000]:\n",
    "    print(n, ':', product)\n",
    "    n = n + 1\n",
    "    sku_id = product[0]\n",
    "    sku_name = product[1]\n",
    "    try:\n",
    "        total_by_date = select_trans(product_quantity_date, sku_id)\n",
    "        flat_result_cv, flat_result_test, preds= adaptive_forecast_process(total_by_date, 'M')\n",
    "        if not flat_result_test:\n",
    "            continue\n",
    "        product_dict = dict(zip(['sku_id', 'sku_name'], product))\n",
    "        flat_result_test.update(product_dict)\n",
    "        for result in flat_result_cv:\n",
    "            result.update(product_dict)\n",
    "        list_preds = list(zip(preds.index, preds))\n",
    "        for pred in list_preds:\n",
    "            pred_arr = [pred[0].isoformat(), pred[1]]\n",
    "            init_attr = dict(product_dict)\n",
    "            init_attr.update({'mape_error': flat_result_test['mape_error'], 'wape_cv': flat_result_test['wape_cv']})\n",
    "            result = dict(zip(['time_predict', 'demand_predict'], pred_arr))\n",
    "            result.update(init_attr)\n",
    "            preds_future.append(result)\n",
    "        flat_test_result_all_product.append(flat_result_test)\n",
    "        flat_cv_result_all_product.extend(flat_result_cv)\n",
    "        json.dump(flat_test_result_all_product, open('json_output/month_flat_test_result_all_product.json', 'w', encoding = 'utf8'))\n",
    "        json.dump(flat_test_result_all_product, open('json_output/month_flat_cv_result_all_product.json', 'w', encoding = 'utf8'))\n",
    "        json.dump(preds_future, open('json_output/month_future_predict_all_product.json', 'w', encoding = 'utf8'))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test_result_all_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
