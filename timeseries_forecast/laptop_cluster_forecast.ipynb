{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_process import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_elastic(flat_result_all_cat, index_name, doctype):\n",
    "    settings = {\n",
    "        \"index\":{\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1,\n",
    "            \"mapping\": {\n",
    "                \"total_fields\":{\n",
    "                    \"limit\": \"1000\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    mapping = {\n",
    "            doctype: { \n",
    "               \"dynamic_templates\": [\n",
    "                   {\"strings\": {\n",
    "                        \"match_mapping_type\": \"string\",\n",
    "                        \"mapping\": {\n",
    "                          \"type\": \"keyword\"\n",
    "                        }\n",
    "                      }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    uri = ['http://{}:{}'.format(ip, '9200') for ip in ['192.168.0.179', '192.168.0.178']]\n",
    "    es = DocTools(uri)\n",
    "    esi = es.indextool()\n",
    "    esi.create(index_name, overwrite = True, settings = settings, mapping = mapping)\n",
    "    res = es.bulk(index_name, flat_result_all_cat, doctype = doctype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_func(group_file):\n",
    "    #load fact\n",
    "    dlf = datalabframework.project.load()\n",
    "    engine = datalabframework.project.engine()\n",
    "    spark = engine.context()\n",
    "    fact_transaction = engine.load('fact_table').select('sku_id', 'sku_name', 'transaction_date', 'quantity', \\\n",
    "                                                        'doc_type', 'unit_price', 'cat_id', 'cat_group_id', \\\n",
    "                                                        'cat_root_id', 'cat_name', 'cat_group_name', 'cat_root_name', \\\n",
    "                                                        'brand_id', 'brand_name')\n",
    "    product_quantity_date = fact_transaction.where(F.expr('doc_type == \"PTX\"') | F.expr('doc_type == \"HDF\"'))\\\n",
    "                .where(F.expr('unit_price != 0'))\\\n",
    "                .groupby('sku_id', 'sku_name', 'transaction_date', 'cat_id', 'cat_group_id', 'cat_root_id', \n",
    "                         'cat_name', 'cat_group_name', 'cat_root_name', 'brand_id', 'brand_name')\\\n",
    "                .agg(F.sum('quantity').alias('daily_quantity'), F.avg('unit_price').alias('daily_price'))\\\n",
    "                .orderBy('transaction_date')\n",
    "    #read group\n",
    "    cluster_group = pd.read_csv(group_file)\n",
    "    cluster_group.columns = ['brand', 'line', 'series', 'price_segment', 'sku_id']\n",
    "    product_quantity_date = product_quantity_date.toPandas()\n",
    "    product_quantity_date['sku_id'] = product_quantity_date['sku_id'].astype(int)\n",
    "    product_quantity_date['daily_quantity'] = product_quantity_date['daily_quantity'].astype(int)\n",
    "    product_quantity_date['transaction_date'] = pd.to_datetime(product_quantity_date['transaction_date'])\n",
    "    cluster_group['sku_id'] = cluster_group['sku_id'].astype(int)\n",
    "    return product_quantity_date, cluster_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trans_group(product_quantity_date, cat_root_name = 'laptop',  group_products = None):\n",
    "    \"\"\"\n",
    "    Select all transactions of a category (or all products) and caculate total sale of this category by date.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    product_quantity_date: Spark.DataFrame\n",
    "        Arregation quantity dataframe of all sku and transaction date\n",
    "    cat_root_name: string\n",
    "        Name of selected root category\n",
    "    group_products: DataFrame\n",
    "        List of selected product\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Spark.DataFrame\n",
    "        Total sales of a category by date\n",
    "    \"\"\"\n",
    "    cat_trans = product_quantity_date[(product_quantity_date['cat_root_name'] == cat_root_name)]\n",
    "    cat_trans =  cat_trans.merge(group_products, on = 'sku_id')\n",
    "    total_by_date = cat_trans.groupby('transaction_date').agg({'daily_quantity':'sum'}).reset_index()\n",
    "    return total_by_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_history_and_forecast(product_quantity_date, cat_root_name, group_sku, attr_dict, freq_ = 'D'):\n",
    "    total_by_date = select_trans_group(product_quantity_date, cat_root_name, group_sku)\n",
    "    if (total_by_date.shape[0] == 0):\n",
    "        return None, None, None, None\n",
    "    flat_result_cv, flat_result_test, hist_data, preds = adaptive_forecast_process(total_by_date, freq_)\n",
    "    if flat_result_test:\n",
    "        flat_result_test.update(attr_dict)\n",
    "        for cv in flat_result_cv:\n",
    "            cv.update(attr_dict)\n",
    "    if hist_data:\n",
    "        for data in hist_data:\n",
    "            data.update(attr_dict)\n",
    "    if preds != None:\n",
    "        for pred in preds:\n",
    "            pred.update(attr_dict)\n",
    "    return flat_result_cv, flat_result_test, hist_data, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(freq_str):\n",
    "    freq_ = 'D'\n",
    "    if freq_str == 'month':\n",
    "        freq_ = 'M'\n",
    "    elif freq_str == 'week':\n",
    "        freq_ = 'W-SUN'\n",
    "    product_quantity_date, cluster_laptop = init_func('csv_folder/cluster_laptop_products.csv')\n",
    "    combination_attr = [['brand'], ['brand', 'line'], ['brand', 'line', 'series'], ['brand', 'price_segment'],\\\n",
    "                        ['brand', 'line', 'price_segment'], ['brand', 'line', 'series', 'price_segment']]\n",
    "    flat_test_result_all_group = []\n",
    "    flat_cv_result_all_group = []\n",
    "    preds_future = []\n",
    "    history_data = []\n",
    "    for comb in combination_attr:\n",
    "        distinct_value_attr_df = cluster_laptop[comb].drop_duplicates().values\n",
    "        n = 0\n",
    "        print('number distint:', len(distinct_value_attr_df))\n",
    "        for value_attr in distinct_value_attr_df:\n",
    "            print('n = ', n, ' ', value_attr)\n",
    "            n += 1\n",
    "            selected_cluster = cluster_laptop\n",
    "            for i, attr in enumerate(comb):\n",
    "                selected_cluster = selected_cluster[selected_cluster[attr] == value_attr[i]]\n",
    "            group_sku_id = selected_cluster[['sku_id']]\n",
    "            attr_dict = dict(zip(['brand', 'line', 'series', 'price_segment'], [None] * 4))\n",
    "            attr_dict.update(dict(zip(comb, value_attr)))\n",
    "            print(attr_dict)\n",
    "            flat_result_cv, flat_result_test, hist_data, preds = caculate_history_and_forecast(product_quantity_date, 'laptop', \\\n",
    "                                                                                               group_sku_id, attr_dict, freq_)\n",
    "            if flat_result_test:\n",
    "                flat_test_result_all_group.append(flat_result_test)\n",
    "            if flat_result_cv:\n",
    "                flat_cv_result_all_group.extend(flat_result_cv)\n",
    "            if hist_data:\n",
    "                history_data.extend(hist_data)\n",
    "            if preds:\n",
    "                preds_future.extend(preds)\n",
    "    json.dump(flat_test_result_all_group, open('json_output/laptop_cluster/' + freq_str+ '/info_test_forecast.json', 'w', encoding = 'utf8'))\n",
    "    json.dump(flat_cv_result_all_group, open('json_output/laptop_cluster/' + freq_str+ '/info_cv_forecast.json', 'w', encoding = 'utf8'))\n",
    "    json.dump(preds_future, open('json_output/laptop_cluster/' + freq_str+ '/future_prediction.json', 'w', encoding = 'utf8'))\n",
    "    json.dump(history_data, open('json_output/laptop_cluster/' + freq_str+ '/history_data.json', 'w', encoding = 'utf8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_test_forecast = json.load(open('json_output/laptop_cluster/' + 'week'+ '/info_test_forecast.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in info_test_forecast:\n",
    "    info['wape_test'] = float(info['wape_test'])\n",
    "    info['wape_cv'] = float(info['wape_cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_future = json.load(open('json_output/laptop_cluster/' + 'week'+ '/future_prediction.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = json.load(open('json_output/laptop_cluster/' + 'week'+ '/history_data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_hist = pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_hist[(pd_hist['brand'] =='HP') & (pd.isna(pd_hist['line'])) & (pd.isna(pd_hist['series'])) & (pd.isna(pd_hist['price_segment']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in preds_future:\n",
    "    if math.isnan(pred['below_error']):\n",
    "        pred['below_error'] = -1.0\n",
    "        pred['upper_error'] = -1.0\n",
    "    if pred['brand'] == 'ASUS':\n",
    "        pred['brand'] = 'Asus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(info_test_forecast, 'week_cluster_laptop_info_test_forecast', 'week_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(preds_future, 'week_cluster_laptop_prediction_future', 'week_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_elastic(history, 'week_cluster_laptop_history_data', 'week_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_quantity_date, cluster_group = init_func('csv_folder/cluster_laptop_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sku_id = cluster_group[(cluster_group['brand'] == 'HP')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(group_sku_id['sku_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"19030456\", \"19030364\", \"1810091\", \"1810978\", \"19030431\", \"19030432\", \"19020005\", \"1702882\", \"18101019\", \"1701726\", \"1701983\", \"18101020\", \"18101021\", \"1700079\", \"1700080\", \"1700131\", \"1702436\", \"1702864\", \"1703322\", \"1800471\", \"1702431\", \"1703473\", \"1800543\", \"1703321\", \"1800472\", \"1805399\", \"1806177\", \"18120012\", \"18120171\", \"1805398\", \"19010044\", \"1700132\", \"1701645\", \"19010177\", \"19010176\", \"1700767\", \"1701094\", \"1701417\", \"1701646\", \"1702317\", \"1702356\", \"1800641\", \"1702536\", \"1702614\", \"1800141\", \"1702535\", \"1805184\", \"1809209\", \"1810092\", \"1809210\", \"1809211\", \"1808428\", \"18120052\", \"1700033\", \"1700835\", \"1700965\", \"1702286\", \"1702287\", \"1702528\", \"1702525\", \"1806168\", \"1702280\", \"1800932\", \"1800581\", \"1806176\", \"1702829\", \"1807526\", \"1808473\", \"1808027\", \"1807525\", \"1807527\", \"18110381\", \"19030342\", \"1809550\", \"1702200\", \"1809549\", \"1701195\", \"1800606\", \"1807494\", \"1700034\", \"1700035\", \"1700172\", \"1700832\", \"1700833\", \"1700834\", \"1700013\", \"1702437\", \"1702421\", \"1702683\", \"1702783\", \"1702621\", \"1800848\", \"1800849\", \"1702620\", \"1704925\", \"1704926\", \"1704927\", \"1800539\", \"1800540\", \"1800541\", \"1807495\", \"1808426\", \"18120051\", \"19010425\", \"19010426\", \"1806192\", \"1806193\", \"1806194\", \"18120015\", \"18120124\", \"18120125\", \"1700015\", \"1700768\", \"1700769\", \"1700771\", \"1701264\", \"1701267\", \"1701828\", \"1602768\", \"1603762\", \"1700016\", \"1700770\", \"1701265\", \"1603758\", \"1603761\", \"1701262\", \"1702686\", \"1702687\", \"1702688\", \"1702615\", \"1702616\", \"1800644\", \"1800846\", \"1800847\", \"1702613\", \"1702617\", \"1704809\", \"1704810\", \"1704811\", \"1704812\", \"1800142\", \"1800612\", \"1800642\", \"1800977\", \"1805173\", \"1702612\", \"1800147\", \"1805462\", \"1806245\", \"1806246\", \"1806247\", \"1807332\", \"1807334\", \"1807333\", \"1807457\", \"1808102\", \"18120010\", \"18120126\", \"18120127\", \"18110331\", \"18120011\", \"1809231\", \"19010043\", \"1809173\", \"1809172\", \"1809326\", \"1809327\", \"1807458\", \"1807459\", \"1702531\", \"1702532\", \"1702420\", \"1805027\", \"1700170\", \"1700171\", \"1702357\", \"1703124\", \"1806213\", \"1702358\", \"1702359\", \"1800470\", \"1800529\", \"1806214\", \"1806215\", \"1702999\", \"1809208\", \"19010042\", \"1701038\", \"1700017\", \"1603756\", \"1701630\", \"1701631\", \"1704805\", \"1809232\", \"1704807\", \"1703319\", \"1704806\", \"1800146\", \"1703320\", \"19030067\", \"19030458\", \"19030066\", \"1700804\", \"1603672\", \"1700842\", \"1800169\", \"1704820\", \"1810516\", \"1703107\", \"1704817\", \"1704815\", \"1800542\", \"1704816\", \"1704818\", \"19030313\", \"19030314\", \"19030315\", \"19030316\", \"1700018\", \"1700839\", \"1701980\", \"1700841\", \"1702199\", \"1603534\", \"1800525\", \"1703106\", \"1703110\", \"1704819\", \"1800524\", \"1800526\", \"1808427\", \"1703108\", \"1703109\", \"19030457\", \"19030299\", \"19030317\", \"19020315\", \"19020316\", \"1704879\", \"1808474\", \"1701451\", \"1704880\", \"1805174\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s) == len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sku in s:\n",
    "    if int(sku) not in t:\n",
    "        print(sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_root_name = 'laptop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_by_date = select_trans_group(product_quantity_date, cat_root_name, group_sku_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_result_cv, flat_result_test, hist_data, preds = adaptive_forecast_process(total_by_date, 'W-SUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_result_cv, flat_result_test, hist_data, preds= caculate_history_and_forecast(product_quantity_date, cat_root_name, group_sku_id, {}, freq_ = 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
